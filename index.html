<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CL â‰ˆ NSCL</title>
    <link rel="icon" type=""image/png" href="lab-logo.png" />

    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>

    <!-- KaTeX CSS + JS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" />
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
      onload="renderMathInElement(document.body, { delimiters: [ {left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false} ] });"></script>

    <!-- Icons (SVG-based) -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />

    <style>
      .fade-in-up {
        opacity: 0;
        transform: translateY(20px);
        transition: opacity 0.6s ease-out, transform 0.6s ease-out;
      }
      .fade-in-up.visible {
        opacity: 1;
        transform: translateY(0);
      }
    </style>
  </head>
  <body class="bg-slate-50 text-slate-800">
    <main class="flex flex-col items-center px-4 py-10 min-h-screen">
      <!-- Hero Section -->
      <section id="hero" class="w-full max-w-5xl text-center fade-in-up">
        <h1 class="mb-4 text-4xl font-extrabold leading-tight md:text-5xl">
          Selfâ€‘Supervised Contrastive Learning <br class="hidden md:block" />
          is Approximately Supervised Contrastive Learning
        </h1>
        <div class="mt-2 space-y-1 text-lg font-medium text-slate-700 md:text-2xl">
          <p>
            <a href="https://achleshwar.github.io/" class="hover:underline" target="_blank">Achleshwar Luthra</a>
            Â· <a href="https://people.tamu.edu/~tianbao-yang/" class="hover:underline" target="_blank">Tianbao Yang</a>
            Â· <a href="https://tomergalanti.github.io/index.html" class="hover:underline" target="_blank">Tomer Galanti</a>
          </p>
          <p class="text-slate-500 font-medium">Texas A&amp;M University</p>
          <p class="text-slate-00 italic">Accepted at NeurIPS 2025ðŸŒ´</p>

        </div>
      </section>

      <!-- Links Section -->
      <section class="mt-10 flex flex-col md:flex-row items-center justify-center gap-8">
        <a href="https://github.com/DLFundamentals/understanding-ssl/" class="flex flex-col items-center hover:scale-105 transition-transform" target="_blank">
          <i class="fab fa-github text-5xl text-slate-800"></i>
          <span class="mt-2 text-md text-slate-600">Code</span>
        </a>
        <a href="https://arxiv.org/abs/2506.04411" class="flex flex-col items-center hover:scale-105 transition-transform" target="_blank">
          <i class="fas fa-file-pdf text-5xl text-indigo-500"></i>
          <span class="mt-2 text-md text-slate-600">Paper</span>
        </a>
      </section>

      <!-- Overview Section -->
      <section class="mt-20 w-full max-w-5xl text-left">
        <h2 class="text-2xl font-bold mb-4">Overview</h2>
        <p class="text-lg mb-4">
          Self-supervised contrastive learning (CL) is everywhere these days. 
          Itâ€™s become a go-to tool for learning useful representations without needing labeled data â€” and it works remarkably well. 
          Models trained with CL often show properties that look a lot like those of supervised models: 
          tight clusters, clean separation between classes, and features that transfer across tasks. But despite 
          how widely itâ€™s used, we still donâ€™t fully understand why it works so well. After all, 
          these models are trained without any labels at all.
        </p>

        <!-- Image Grid -->
        <div class="overflow-x-auto">
          <!-- Top row: DCL -->
            <div class="grid grid-cols-6 gap-2 mb-4">
                <img src="./images/umap/umap_imagenet_dcl_random.png" alt="DCL Random" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_dcl_epoch10.png" alt="DCL Epoch 10" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_dcl_epoch100.png" alt="DCL Epoch 100" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_dcl_epoch500.png" alt="DCL Epoch 500" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_dcl_epoch1000.png" alt="DCL Epoch 1000" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_dcl_epoch1900.png" alt="DCL Epoch 1900" class="w-full object-contain rounded shadow transition hover:scale-105" />
            </div>
            
            <!-- Bottom row: NSCL -->
            <div class="grid grid-cols-6 gap-2 mb-2">
                <img src="./images/umap/umap_imagenet_nscl_random.png" alt="NSCL Random" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_nscl_epoch10.png" alt="NSCL Epoch 10" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_nscl_epoch100.png" alt="NSCL Epoch 100" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_nscl_epoch500.png" alt="NSCL Epoch 500" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_nscl_epoch1000.png" alt="NSCL Epoch 1000" class="w-full object-contain rounded shadow transition hover:scale-105" />
                <img src="./images/umap/umap_imagenet_nscl_epoch1900.png" alt="NSCL Epoch 1900" class="w-full object-contain rounded shadow transition hover:scale-105" />
            </div>
  

          <div class="grid grid-cols-6 text-center text-sm text-slate-500 mt-4">
            <span>Init</span>
            <span>Epoch 10</span>
            <span>Epoch 100</span>
            <span>Epoch 500</span>
            <span>Epoch 1000</span>
            <span>Epoch 2000</span>
          </div>

          <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
            Figure 1: <strong>Self-supervised CL (top)</strong> forms semantic clusters without label supervision, while 
            <strong>supervised CL (bottom)</strong> yields tighter, more separable clusters.
          </p>
        </div>

        <p class="mt-6 text-lg">
          This behavior raises the following question:
        </p>

        <div class="fade-in-up mx-auto my-8 w-full max-w-3xl rounded-md border border-black bg-indigo-50 px-6 py-4 text-center text-lg italic text-slate-800 shadow-sm">
          <strong>
            How does self-supervised CL learn representations similar to supervised learning, despite lacking explicit supervision?
          </strong>
        </div>

        <p class="text-lg">
          In order to address this question, we study the relationship between CL and supervised 
          contrastive learning (SCL). We show that the popular <strong>CL objective implicitly optimizes a
          supervised contrastive loss (SCL)</strong>. 
        </p>
      </section>
    
      <!-- Key Claims -->
      <section class="mt-20 w-full max-w-5xl text-left">
        <h2 class="text-2xl font-bold mb-6">Key Observations</h2>

        <!-- Claim 1 -->
        <div class="mb-10 p-6 border rounded-md shadow-sm bg-white fade-in-up">
            <h3 class="text-xl font-semibold mb-4">1 Â· CL â‰ˆ NSCL</h3>
            <p class="mb-4">
            Our first observation suggests that the global <span class="text-blue-700 font-medium">Contrastive Loss</span> (NTXent)
            used in SSL is closely related to a supervised loss which we refer to as
            <span class="text-red-600 font-medium">Negatives-only Supervised Contrastive Loss (NSCL)</span>.
            Specifically, the gap between the two losses is at most $O(1/C)$ as shown below.
            </p>

            <p class="mb-2">
              $$0 \leq \left| \textcolor{blue}{\mathcal{L}^{\text{CL}}} - \textcolor{red}{\mathcal{L}^{\text{NSCL}}} \right| \leq \log\left(1 + \frac{e^2}{C - 1}\right)$$
            </p>
            <p class="text-sm italic text-right text-slate-500 mb-4">Theorem (1)</p>
            
            
            <div class="flex flex-col md:flex-row gap-4 mb-4">
              <!-- DCL Equation -->
              <div class="border-2 border-blue-600 bg-slate-50 rounded p-4 text-sm flex-1 hover:border-blue-300">
                $$\small
                \mathcal{L}^{\mathrm{CL}}(f) = -\frac{1}{K^2N}\sum^{K}_{l_1,l_2=1}\sum_{i=1}^N
                \log \left(
                \frac{\exp(\mathrm{sim}(z^{l_1}_i, z^{l_2}_i))}{
                \sum^{K}_{l_3=1} \textcolor{blue}{\sum_{j\in [N]\setminus \{i\}}} \exp (\mathrm{sim}(z^{l_1}_i, z^{l_3}_j)) }
                \right)
                $$
              </div>

              <!-- NSCL Equation -->
              <div class="border-2 border-red-600 bg-slate-50 rounded p-4 text-sm flex-1 hover:border-red-300">
                $$\small
                \mathcal{L}^{\mathrm{NSCL}}(f) = -\frac{1}{K^2N}\sum^{K}_{l_1,l_2=1}\sum_{i=1}^N
                \log \left(
                \frac{\exp(\mathrm{sim}(z^{l_1}_i, z^{l_2}_i))}{
                \sum^{K}_{l_3=1} \textcolor{red}{\sum_{j: y_j \neq y_i}} \exp (\mathrm{sim}(z^{l_1}_i, z^{l_3}_j)) }
                \right)
                $$
              </div>
            </div>


            <ul class="list-disc list-inside text-sm text-slate-600 space-y-1">
            <li><strong>$\mathrm{sim(\cdot, \cdot)}$</strong> denotes cosine similarity</li>
            <li><strong>$N$</strong>: Total number of <strong>training</strong> samples</li>
            <li><strong>$K$</strong>: Total number of augmented versions of each sample</li>
            <li><strong>$z^l_i = f(\alpha_k(x_i))$</strong>, where <strong>$x_i$</strong> is an input image
              and <strong>$\alpha_k$</strong> is its $k^{th}$ augmentation.</li>
            </ul>
        </div>

        <p class="text-lg mb-4">
          To validate Thm. (1), we track the losses during training on CIFAR-100, and miniâ€‘ImageNet for <em>2k</em> epochs. 
          The empirical gap between the two losses shrinks as the number of classes grows and 
          <span class="text-blue-600 font-medium">CL</span> remains tightly bounded by <span class="text-red-600 font-medium">NSCL</span> 
          + <span class="text-slate-600 font-medium">$\log\left(1 + \frac{e^2}{C - 1}\right)$.</span>
        </p>
        
        <!-- Image grid -->
        <div class="mt-10 grid grid-cols-1 md:grid-cols-2 gap-6">
          <div class="flex flex-col items-center">
            <img src="./images/exp1/cifar100_simclr_losses.png" alt="CIFAR-10" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(a) CIFAR100</span>
          </div>
          <div class="flex flex-col items-center">
            <img src="./images/exp1/imagenet_simclr_losses.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(b) mini-ImageNet</span>
          </div>
        </div>
        <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
          Figure 2: Validating Thm. (1) as a function of training epochs.
        </p>

        <p class="text-lg mb-4 mt-10">
          In another attempt to verify Thm. (1), we randomly sample $C$ classes from each dataset and train a new
          SSL model on the subsets corresponding to those classes. We observe that the empirical gap between the two losses exponentially decays
          as the number of classes increases, and the gap is highly correlated with <span class="text-slate-600 font-medium">$\log\left(1 + \frac{e^2}{C - 1}\right)$.</span>
        </p>

        <div class="mt-10 grid grid-cols-1 md:grid-cols-2 gap-6">
          <div class="flex flex-col items-center">
            <img src="./images/exp2/th1_exp2_cifar100.png" alt="CIFAR-10" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(a) CIFAR100</span>
          </div>
          <div class="flex flex-col items-center">
            <img src="./images/exp2/th1_exp2_imagenet.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(b) mini-ImageNet</span>
          </div>
        </div>
        <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
          Figure 3: Validating Thm. (1) as a function of semantic classes ($C$).
        </p>

        <p class="text-lg mb-4 mt-10">
          Great! We have established that the CL objective is approximately equal to NSCL but ...
        </p>

        <!-- Claim 2 -->
        <div class="mt-10 mb-10 p-6 border rounded-md shadow-sm bg-white fade-in-up">
          <h3 class="text-xl font-semibold mb-2">2 Â· Why care about NSCL?</h3>
          <p class="mb-4">
          <strong>NSCL minimizers yield collapse + simplex ETF geometry.</strong>
          At the global minimum of the NSCL loss, representations exhibit:
          </p>
          <ul class="list-none list-inside text-base text-slate-800 space-y-2 mb-2">
          <li><strong>(i) Augmentation Collapse:</strong> All augmented views of a sample map to the same point.</li>
          <li><strong>(ii) Within-Class Collapse:</strong> All samples from the same class share an identical embedding.</li>
          <li><strong>(iii) Simplex ETF Geometry:</strong> Class means form a symmetric equiangular tight frame in feature space.</li>
          </ul>
          <p class="text-sm italic text-right text-slate-500">Theorem (2)</p>
      </div>

      <p class="text-lg mb-4 mt-10">
        To evaluate the quality of representations learned by $\mathrm{NSCL}$ objective, we report NCCC error
        and linear probing error on few-shot classification tasks. 1â€‘shot linear probing accuracy exceeds 70â€¯% on CIFAR-100
        and miniâ€‘ImageNet, while 1-shot NCCC exceeds 90â€¯% on CIFAR10. 

        </p>
    
      <!-- Image grid -->
      <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mt-10">
        <div class="flex flex-col items-center">
          <img src="./images/exp3_nscl/few_shot_error_analysis_cifar10.png" alt="CIFAR-10" class="w-full object-contain rounded shadow transition hover:scale-105" />
          <span class="mt-2 text-sm text-slate-500">(a) CIFAR10</span>
        </div>
        <div class="flex flex-col items-center">
          <img src="./images/exp3_nscl/few_shot_error_analysis_cifar100.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
          <span class="mt-2 text-sm text-slate-500">(b) CIFAR100</span>
        </div>
        <div class="flex flex-col items-center">
          <img src="./images/exp3_nscl/few_shot_error_analysis_imagenet.png" alt="mini-ImageNet" class="w-full object-contain rounded shadow transition hover:scale-105" />
          <span class="mt-2 text-sm text-slate-500">(c) mini-ImageNet</span>
        </div>
      </div>
      <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
        Figure 4: Downstream performance of a model $f$ trained with NSCL objective on few-shot classification tasks.
      </p>
      </div>
      
      <!-- Motivation for CDNV and dir-CDNV -->
      <p class="text-lg mb-4 mt-10">
        In short, NSCL-training performs well! 
        <br><br>
        Theorem 2 implies that <span class="text-red-600 font-medium">NSCL</span> yields perfectly clustered representations, 
        which in turn allow us to easily infer the labels from the learned model. 
        <!-- However, our goal is to better understand <span class="text-blue-600 font-medium">self-supervised CL</span>, not its supervised counterpart.  -->
        This raises the following question: 
        <div class="fade-in-up mx-auto my-8 w-full max-w-3xl rounded-md border border-black bg-indigo-50 px-6 py-4 text-center text-lg italic text-slate-800 shadow-sm">
          <strong>
            Can we come up with an error bound based on the geometric properties of representations that explains transferability?
          </strong>
        </div>
      </p>

      <p class="text-lg mb-4 mt-10">
        Estimating the downstream error of NSCL-trained models is fairly simply.
        Suppose we have a downstream task with two classes (for eg: cats and dogs) with distributions $D_1$ and $D_2$,
        and a pre-trained model $f$, we measure the downstream performance $\mathrm{err}_{m,D}(f)$ as the test performance 
        of a linear probe trained on top of $f$ using $m$ random samples per class. 
        <a href="https://arxiv.org/pdf/2112.15121" target="_blank" class="text-blue-600 underline">One approach</a> 
        for estimating this bound is to use the <strong>class-distance-normalized variance (CDNV)</strong>.
        <br><br>
        For a model $f$, and two class-conditional distributions $D_1$ and $D_2$, the CDNV is defined as:
        $$V_{f}(D_1, D_2) = \frac{\text{Intra-class variance}}{\left(\text{Inter-class distance}\right)^2}$$
      </p>

      <!-- CDNV  Visualization -->
      <div class="flex flex-col md:flex-row items-center gap-6 mt-20 items-start">
        <!-- Image column -->
        <div class="md:w-1/2 w-full">
          <img src="./images/cdnv_viz.png" alt="Descriptive alt" class="w-full rounded" />
        </div>
      
        <!-- Text column -->
        <div class="md:w-1/2 w-full text-left space-y-4">
          <h6 class="text-xl font-semibold mb-2">Intra-class variance:</h6>
          <p class="text-slate-700">
            Intra-class variance quantifies how tightly the samples are packed around their class-center. 
            Smaller intra-class variance implies more compact representations of a given class.
          </p>

          <h6 class="text-xl font-semibold mb-2">Inter-class distance:</h6>
          <p class="text-slate-700">
            Inter-class distance measures how far apart the class-centers are in the embedding space.
          </p>

          <div class="mt-6 pt-4 border-t border-gray-300">
            <h6 class="text-xl font-semibold mb-2">What CDNV captures:</h6>
            <p class="text-slate-700">
              CDNV balances these two forcesâ€”compactness vs. separationâ€”and is minimized when clusters are tight
              and well-separated.
            </p>
          </div>
        </div>
      </div>

      <p class="text-lg mb-4 mt-10">
        A low CDNV value is associated with better downstream performance.
        <a href="https://arxiv.org/pdf/2112.15121" target="_blank" class="text-blue-600 underline">For instance,</a>
        the few-shot classification error, $\mathrm{err}_{m,D}(f)$, trained on a data 
        distribution $D$ with $m$ labeled samples per class can be bounded as follows:
      </p>

      <div class="relative mb-4">
        <p class="text-center">
          $$
          \mathrm{err}_{m,D}(f)
          \lesssim
          (1 + \tfrac{1}{m}) \, V_{f}(D_1,D_2) 
          $$
        </p>
        <span class="absolute right-0 top-1/2 -translate-y-1/2 text-sm italic text-slate-500">
          (Eqn. 1)
        </span>
      </div>
      
      
      
      <p class="text-lg mb-4 mt-10">
        Eqn. (1) explains the strong few-shot performance of NSCL (shown in Figure 4) as Thm. (2) implies that
        NSCL minimizes the CDNV term, which further minimizes
        the few-shot classification error.
      </p>
      
      <!-- Introduce directional CDNV -->
      <p class="text-lg mb-4 mt-10">
        But wait, 
        <strong>
          is CDNV good enough to exlain transferability in SSL?
        </strong>
        Not quite. CDNV is great if you assume near-perfect clusteringâ€” <em>*each class*</em>
        forming a tight, spherical blob. But that's a pretty strong assumption, especially 
        in SSL where no labels guide the geometry. So instead, we introduce a weaker notion
        of clustering: <strong>directional class-distance-normalized variance (dir-CDNV)</strong>.
      </p>

      <p class="text-lg mb-4 mt-10">
        For a model $f$, and two class-conditional distributions $D_1$ and $D_2$, the dir-CDNV is defined as:
        $$\tilde{V}_f(D_1,D_2) = \frac{\text{Projected variance}}{\left(\text{Inter-class distance}\right)^2}$$
      </p>

      <!-- Directional CDNV  Visualization -->
      <div class="flex flex-col md:flex-row items-center gap-6 mt-20 items-start">
        <!-- Image column -->
        <div class="md:w-1/2 w-full">
          <img src="./images/directional_cdnv_viz.png" alt="Descriptive alt" class="w-full rounded" />
        </div>
      
        <!-- Text column -->
        <div class="md:w-1/2 w-full text-left space-y-4">
          <h6 class="text-xl font-semibold mb-2">Projected variance:</h6>
          <p class="text-slate-700">
            Projected variance (or directional variance) measures variance only along the direction between class centers.
            Instead of using full isotropic distance from a point to its class center, we project each point onto the unit 
            direction <span class="text-blue-700 font-medium">(shown in blue)</span> connecting class centers.
            
          </p>

          <div class="mt-6 pt-4 border-t border-gray-300">
            <h6 class="text-xl font-semibold mb-2">What dir-CDNV captures:</h6>
            <p class="text-slate-700">
              dir-CDNV captures how spread out the points are in the discriminative direction.
            </p>
          </div>
        </div>
      </div>

      <p class="text-lg mb-4 mt-10">
        We analyze both variance terms for both CL and NSCL models on CIFAR-100, and miniâ€‘ImageNet.
        During training, we observe that CDNV decreases significantly for NSCL but it remains relatively high for CL.
        However, dir-CDNV decreases for both CL and NSCL models, indicating that both models learn to 
        reduce the spread of points in the discriminative direction.
      </p>

      <!-- Image grid -->
      <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mt-10">
        <div class="flex flex-col items-center">
          <img src="./images/cdnv/cifar100_cdnv.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
          <span class="mt-2 text-sm text-slate-500">(a) CIFAR100</span>
        </div>
        <div class="flex flex-col items-center">
          <img src="./images/cdnv/imagenet_cdnv.png" alt="mini-ImageNet" class="w-full object-contain rounded shadow transition hover:scale-105" />
          <span class="mt-2 text-sm text-slate-500">(b) mini-ImageNet</span>
        </div>
      </div>
      <p class="text-sm text-slate-500 text-center max-w-4xl mx-auto italic mt-4">
        Figure 5: Analysis of CDNV and dir-CDNV during training.
      </p>
      <p class="text-lg mb-4 mt-10">
        So why go through all this trouble defining directional CDNV?
        Because it turns outâ€”this is the term that actually controls how well we can recover labels from representations,
        as we show in the next section.
      </p>

      <!-- Claim 4 -->
      <div class="mt-20 mb-10 p-6 border rounded-md shadow-sm bg-white fade-in-up">
          <h3 class="text-xl font-semibold mb-4">3 Â· Recoverability of Labels</h3>
          <p class="mb-4">
          Our key insight is that  <em>few-shot classification error</em> is governed by two geometric variance terms, with the
          <strong>dirâ€‘CDNV</strong> playing the dominant role.
          </p>

          Formally,
          <p class="text-base mb-2">$$
            \mathrm{err}_{m,D}(f)
            \lesssim
            \textcolor{purple}{\tilde{V}_f(D_1,D_2)} + \tfrac{1}{m}\,\textcolor{orange}{V_{f}(D_1,D_2)}
        $$</p>
        <p class="text-sm italic text-right text-slate-500 mb-4">Proposition (1)</p>

          <p class="mb-2">
          As the number of labeled samples per class $m$ increases, the influence of the
          standard CDNV diminishes, leaving dâ€‘CDNV as the main driver of performance.
          </p>

          <p class="text-center font-semibold text-blue-700 mb-4">Low dâ€‘CDNV â‡’ strong transfer from unlabeled to labeled data.</p>

        <div class="mb-4">
          
          <p >Definitions of the variance terms used in Proposition (1):</p>
          <div class="text-sm text-slate-600">
            <div class="flex flex-col md:flex-row gap-4">
              <!-- CDNV -->
              <div class="border-2 border-orange-300 bg-slate-50 rounded p-4 text-sm flex-1 hover:border-orange-600">
                <p class="whitespace-nowrap">
                  $$V_f(D_1, D_2) = \frac{\sigma_1^2}{\|\mu_1 - \mu_2\|^2}$$
                </p>
                <p class="whitespace-nowrap">
                  $$\sigma_{1}^{2} = \operatorname{Var}_{x \sim D_1} [ f(x) ]$$
                </p>
              </div>
          
              <!-- Directional CDNV -->
              <div class="border-2 border-purple-600 bg-slate-50 rounded p-4 text-sm flex-1 hover:border-purple-300">
                <p class="whitespace-nowrap">
                  $$\tilde{V}_f(D_1, D_2) = \frac{\sigma_{12}^2}{\|\mu_1 - \mu_2\|^2}$$
                </p>
                <div class="flex flex-col md:flex-row items-center gap-6 mt-6">
                  <p class="whitespace-nowrap">
                    $$\sigma_{12}^{2} = \operatorname{Var}_{x \sim D_1} [ \langle f(x) - \mu_1, u_{12} \rangle ]$$
                  </p>
                  <p class="whitespace-nowrap">
                    $$u_{12} = \frac{\mu_1 - \mu_2}{\|\mu_1 - \mu_2\|^2}$$
                  </p>
                </div>
                
              </div>
            </div>
          </div>

          <div class="space-y-1">
                <p>Other terms:</p>
                <ul class="list-disc list-inside">
                <li>$D_i$: Class-conditional distribution for class $i$</li>
                <li>$m$: Number of labeled samples per class (i.e., number of shots)</li>
                </ul>
          </div>
        </div>
        </div>
      </div>
      
    <p class="text-lg mb-4">
      We validate Proposition (1) by tracking the few-shot performance of linear probes and NCCC on CIFAR-10, CIFAR-100, and miniâ€‘ImageNet.
      The error bound goes down to 0.25 for CIFAR-10 at a very large m, shown in red below.
    </p>
  
    <!-- Image grid -->
    <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mt-10">
      <div class="flex flex-col items-center">
        <img src="./images/error/error_analysis_cifar10.png" alt="CIFAR-10" class="w-full object-contain rounded shadow transition hover:scale-105" />
        <span class="mt-2 text-sm text-slate-500">(a) CIFAR10</span>
      </div>
      <div class="flex flex-col items-center">
        <img src="./images/error/error_analysis_cifar100.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
        <span class="mt-2 text-sm text-slate-500">(b) CIFAR100</span>
      </div>
      <div class="flex flex-col items-center">
        <img src="./images/error/error_analysis_imagenet.png" alt="mini-ImageNet" class="w-full object-contain rounded shadow transition hover:scale-105" />
        <span class="mt-2 text-sm text-slate-500">(c) mini-ImageNet</span>
      </div>
    </div>

        <!-- <p class="text-lg mb-4">
          We validate Proposition (1) by tracking the few-shot performance of linear probes and NCCC on CIFAR-10, CIFAR-100, and miniâ€‘ImageNet.
          The error bound goes down to 0.25 for CIFAR-10 at a very large m, shown in red below.
        </p> -->

        <!-- Image grid --> 
        <!-- <div class="mt-4 grid grid-cols-1 md:grid-cols-3 gap-6">
          <div class="flex flex-col items-center">
            <img src="./images/exp2/cifar10_error_analysis.png" alt="CIFAR-10" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(a) CIFAR10</span>
          </div>
          <div class="flex flex-col items-center">
            <img src="./images/exp2/cifar100_error_analysis.png" alt="CIFAR-100" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(b) CIFAR100</span>
          </div>
          <div class="flex flex-col items-center">
            <img src="./images/exp2/imagenet_error_analysis.png" alt="mini-ImageNet" class="w-full object-contain rounded shadow transition hover:scale-105" />
            <span class="mt-2 text-sm text-slate-500">(c) mini-ImageNet</span>
          </div>
        </div> -->

      </section>

        <!-- Experiments Section -->

    </section>
        <!-- Experiments Section -->
      <!-- <section class="mt-20 w-full max-w-5xl text-left">
        <h2 class="text-2xl font-bold mb-6">Experiments at a Glance</h2> -->
        <!-- Experiment Card 1 -->
        <!-- <div class="mt-10 bg-white rounded-xl border border-slate-200 p-6 shadow-md fade-in-up">
            <h3 class="text-xl font-semibold mb-4">Tracking the losses</h3>
            <ul class="list-disc list-inside text-slate-700 mb-6 space-y-1">
              <li>DCL and NSCL losses remain tightly coupled across 2k training epochs on CIFAR-10, CIFAR-100, and miniâ€‘ImageNet.</li>
              <li>The empirical gap shrinks as the number of classes grows (noticeable across datasets).</li>
            </ul>
          </div> -->

        <!-- Experiment Card 2 -->
        <!-- <div class="mt-10 bg-white rounded-xl border border-slate-200 p-6 shadow-md fade-in-up">
            <h3 class="text-xl font-semibold mb-4">Few-shot performance</h3>
            
          </div> -->

        <!-- Experiment Card 3 -->
        <!-- <div class="mt-10 bg-white rounded-xl border border-slate-200 p-6 shadow-md fade-in-up">
            <h3 class="text-xl font-semibold mb-4">Error bound</h3>
          </div>
         -->
          <!-- Experiment Card 3 -->
        <!-- <div class="mt-10 bg-white rounded-xl border border-slate-200 p-6 shadow-md fade-in-up">
            <h3 class="text-xl font-semibold mb-4">Geometry of learned representations</h3>
            <ul class="list-disc list-inside text-slate-700 mb-6 space-y-1">
                <li>Directional CDNV drops by ~10Ã— during CL training, while standard CDNV decreases only modestly</li>
                <li>For NSCL, both CDNV and directional CDNV drop significantly</li>
            </ul>
          
          </div>

      </section> -->

      <!-- Final Remarks Section -->
      <section class="mt-20 w-full max-w-5xl text-left fade-in-up">
        <h2 class="text-2xl font-bold mb-4">Final Remarks</h2>

        <p class="text-lg leading-relaxed text-slate-700 mb-6">
            Our work takes several steps toward a better understanding of self-supervised learning, both theoretically and empirically.
            We provide a principled explanation for CLâ€™s success in few-shot learning and identify the geometric structure that underlies
            high-performing representations.
        </p>

        <p class="mb-4 text-lg font-medium text-slate-800">Interested in the details?</p>

        <div class="flex flex-col md:flex-row gap-4">
            <a href="https://arxiv.org/abs/2506.04411" target="_blank"
            class="px-6 py-3 text-white bg-indigo-600 hover:bg-indigo-700 rounded text-center font-medium transition">
            Read the Paper (arxiv)
            </a>
            <a href="https://github.com/DLFundamentals/understanding-ssl/" target="_blank"
            class="px-6 py-3 border border-indigo-600 text-indigo-600 hover:bg-indigo-50 rounded text-center font-medium transition">
            View Code on GitHub
            </a>
        </div>

      </section>

    <section id="bibtex" class="mt-24 max-w-5xl w-full fade-in-up">
        <h2 class="text-2xl font-bold mb-4">BibTeX</h2>

        <div class="relative">
            <!-- BibTeX block -->
<pre id="bibtex-entry" class="bg-slate-900 text-green-200 p-4 rounded overflow-x-auto text-sm leading-relaxed font-mono">
@misc{luthra2025selfsupervisedcontrastivelearningapproximately,
title={Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning}, 
author={Achleshwar Luthra and Tianbao Yang and Tomer Galanti},
year={2025},
url={https://arxiv.org/abs/2506.04411}, 
}
</pre>

            <!-- Copy button -->
            <button onclick="copyBibtex()" class="absolute top-2 right-2 px-2 py-1 text-xs bg-slate-800 text-white border border-slate-700 rounded hover:bg-slate-700 transition">
            Copy
            </button>
        </div>
    </section>


      <!-- Footer -->
      <footer class="mt-20 border-t pt-6 text-center text-sm text-slate-500">
        Â© 2025 Built with â˜•. <br />
        Contact: <a href="mailto:luthra@tamu.edu" class="underline">luthra@tamu.edu</a>
        &middot; <a href="mailto:galanti@tamu.edu" class="underline">galanti@tamu.edu</a>
      </footer>
    </main>

    <!-- Animate on Scroll -->
    <script>
      const observer = new IntersectionObserver(
        (entries) => {
          entries.forEach((entry) => {
            if (entry.isIntersecting) {
              entry.target.classList.add('visible');
            }
          });
        },
        { threshold: 0.1 }
      );

      document.querySelectorAll('.fade-in-up').forEach((el) => observer.observe(el));

    function copyBibtex() {
        const text = document.getElementById("bibtex-entry").innerText;
        navigator.clipboard.writeText(text).then(() => {
            // alert("ðŸ“‹ BibTeX copied to clipboard!");
        });
        }

    </script>
  </body>
</html>